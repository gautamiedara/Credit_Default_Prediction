# Credit_Default_Prediction
Financial institutions need to measure the risks and perform analysis within their credit portfolios (like radio/television, education, car loans, business loans etc.) which will help the lender determine the borrower’s ability to meet the debt obligations. If the borrower is not able to return the credit borrowed within the stipulated timelines, then it means the borrower has defaulted and the financial institution is impacted. To avoid losses, the financial institution should avoid lending credit to potential defaulters. There is a grey area, to predict who and when will a lender default on borrowings. It is the process of intelligent credit analysis that can help mitigate the severity of the complete loss of the borrowings and their recovery. To meet these requirements financial institutions increasingly rely on several models and algorithms to predict losses resulting from customers' defaults. Hence, developing sufficiently accurate and robust models is one of the major efforts of quantitative risk management groups within these institutions.
This project is to develop a robust and efficient model for the credit default risk problem. Specifically, the focus is on developing different models likes logistic regression, classification trees, random forest, gradient boosting method to check the accuracy, F1 score and to predict the classification of the borrower as good or bad using the R language. The goal of the solution is to predict defaulters ahead of time and reduce the financial risk of the firms.

The data is taken from https://archive.ics.uci.edu where public datasets are available and can be used easily. The dataset was checked for null values, data discrepancy, and data types. Some of the columns had a single quote separating the text which was replaced with blank text using MS Excel and uploaded to R-studio to reduce the cleaning effort, it has a total number of 21 variables and 1000 observations. The data defines the purpose of credit, the borrower’s checking, and saving account status, years of employment etc. All the categorical variables were factored in for the model. All these details will help in categorising the person’s class to predict if the person will return the borrowed amount. The details of the dataset and column description can be found in the URL link - https://archive.ics.uci.edu/ml/datasets/Statlog+%28German+Credit+Data%29

## Continuous/Numerical Data Distribution
Data analysis was performed to check the distribution of the data for columns like duration of months for credit taken, credit amount, age is right-skewed indicating instalment that maximum borrowers are younger and take less amount of credit for a lesser duration. Most of the credit amount which is taken varies from 0 to 10000 dollars and the age group varies from 20 to 55 years. Data also shows that the maximum borrower’s instalment rate in percentage of disposable income is around 4% and the borrower already has one existing credit and one dependent relying on them. Outliers’ detection is done using a boxplot, the outliers are present in columns like duration, credit amount, rate of instalment, age, number of existing credits. If these outliers are removed, we will ignore the anomaly present in data which might indicate the borrower’s record of who defaults the credit and hence the outliers will be kept in the dataset for modelling purposes.

## Categorical Data Distribution
The categorical data describes the purpose of the credit taken by the borrower with their gender, marital status, checking account, saving account and credit history. Details like the payment plans, loan guarantors and housing are also present to understand the liability of the person taking the credit. The data also has their details about years of experience, category of the job and if the person works in a foreign country. Apart from this, the class variable indicates whether the borrower is repaying the credit on time, aka, good or bad respectively. Overall, it is seen more radio/tv, car and furniture loan credits in comparison to domestic appliances, retraining and repairs. Single Males take more loans than females and most of the borrowers have skilled jobs and are foreign workers. Maximum borrowers have less than 100 dollars saving account and no checking account status is available.

## Target and Predictor Selection for Model
Collinearity can arise when two or more quantitative predictors are highly correlated. A correlation matrix is created to check if there exists inter-association or inter-relation between two or more independent variables. According to the correlation matrix, there is no correlation among the quantitative variables hence all the numerical variables and other categorical variables will be used as predictors in the model. The class variable will be the target variable using which the prediction of good or bad can be made; bad being credit defaulter and good being non-defaulter.

## Model Selection & Methodology
### Feature Selection
The prediction highly depends on the chosen predictors for the model. A random forest model is used to check the variable importance and to select the best features for the model. The variable importance graph was used to select the predictors. For example, the variable payment plan if the borrower is an important predictor to classify the borrowers as good, but this variable is not important for predicting the defaulted borrower as the value is negative, so such variables are removed from the model as predicting a bad borrower is more crucial than predicting a good borrower. Finally, out of twenty predictors, sixteen predictors were chosen.

The data set is split into train and test data i.e., 70% and 30% respectively and the model with an equation of form 𝑌=𝑓(𝑋) was run, where 𝑌 in the model is a categorical variable. 𝑌={𝑏𝑎𝑑,𝑔𝑜𝑜𝑑} 𝑖.𝑒.,𝐼𝑓 𝑏𝑎𝑑 𝑡ℎ𝑒𝑛 𝑑𝑒𝑓𝑎𝑢𝑙𝑡𝑒𝑟 𝑒𝑙𝑠𝑒 𝑖𝑓 𝑔𝑜𝑜𝑑 𝑛𝑜𝑡 𝑎 𝑑𝑒𝑓𝑎𝑢𝑙𝑡𝑒𝑟 𝑋={𝑐ℎ𝑒𝑐𝑘𝑖𝑛𝑔_𝑎𝑐𝑐𝑜𝑢𝑛𝑡_𝑠𝑡𝑎𝑡𝑢𝑠 ,𝑑𝑢𝑟𝑎𝑡𝑖𝑜𝑛_𝑚𝑜𝑛𝑡ℎ𝑠 ,𝑐𝑟𝑒𝑑𝑖𝑡_ℎ𝑖𝑠𝑡𝑜𝑟𝑦,𝑐𝑟𝑒𝑑𝑖𝑡_𝑝𝑢𝑟𝑝𝑜𝑠𝑒,𝑐𝑟𝑒𝑑𝑖𝑡_𝑎𝑚𝑜𝑢𝑛𝑡,𝑠𝑎𝑣𝑖𝑛𝑔𝑠_𝑎𝑐𝑐𝑜𝑢𝑛𝑡_𝑠𝑡𝑎𝑡𝑢𝑠 ,𝑦𝑒𝑎𝑟𝑠_𝑜𝑓_𝑒𝑚𝑝𝑙𝑜𝑦𝑚𝑒𝑛𝑡 ,𝑟𝑎𝑡𝑒_𝑜𝑓_𝑖𝑛𝑠𝑡𝑎𝑙𝑙𝑚𝑒𝑛𝑡,𝑝𝑒𝑟𝑠𝑜𝑛𝑎𝑙_𝑠𝑡𝑎𝑡𝑢𝑠 ,𝑜𝑡ℎ𝑒𝑟_𝑝𝑎𝑟𝑡𝑖𝑒𝑠,𝑦𝑒𝑎𝑟𝑠_𝑜𝑓_𝑟𝑒𝑠𝑖𝑑𝑒𝑛𝑐𝑒 ,𝑝𝑟𝑜𝑝𝑒𝑟𝑡𝑦_𝑚𝑎𝑔𝑛𝑖𝑡𝑢𝑑𝑒 ,𝑎𝑔𝑒 ,𝑜𝑡ℎ𝑒𝑟_𝑝𝑎𝑦𝑚𝑒𝑛𝑡_𝑝𝑙𝑎𝑛𝑠 ,ℎ𝑜𝑢𝑠𝑖𝑛𝑔 ,𝑛𝑢𝑚_𝑒𝑥𝑖𝑠𝑡𝑖𝑛𝑔_𝑐𝑟𝑒𝑑𝑖𝑡𝑠,𝑛𝑢𝑚_𝑑𝑒𝑝𝑒𝑛𝑑𝑒𝑛𝑡𝑠 ,𝑜𝑤𝑛_𝑡𝑒𝑙𝑒𝑝ℎ𝑜𝑛𝑒 ,𝑓𝑜𝑟𝑒𝑖𝑔𝑛_𝑤𝑜𝑟𝑘𝑒𝑟 }

## Model Selection
### Logistic Regression
Five iterations were run by the model to find the coefficients that best fit the data. The summary of the model depicts the coefficients of each numerical variable, and the odds are defined for the categorical variables. If we consider age, then the determined p-value is 0.96, so the confidence level of age is 4%, which is very less hence it is statistically not significant. Whereas, when we take a categorical variable example like credit account status, containing several categories, if the p-value of either of the categories is significant then the variable is considered in the model.

Finally, after two iterations the final logistic model has ten significant predictors. The numerical predictor like duration in months indicates that as the number of months increases, the probability of the borrower to default payment also increases. For categorical predictors like checking account status, when the status is not present/available then the probability of the borrower being defaulter increases by 1.595. Overall, the probability of being a defaulter is more when the borrower has no checking account status, has a low saving account balance, lesser credit amount, the duration of payment months is high, the borrower has an existing credit and if that purpose of credit was for purchasing of a new car. These are some of the factors defining a credit defaulter.

### Classification Trees
Ten iterations are run where the overfitted tree is created using a very low complexity parameter. Each time the iteration runs the best complexity parameter value is picked where the error is minimum, and the model is re-run with the best complexity parameter value and then, out of sample performance is checked, to obtain the best prediction. The resultant model is then tested using test data, the cp value and F1 score are stored in a list. Finally, the cp value where the corresponding F1 score is highest is chosen and the model is run. The best F1 score is obtained for the classification tree using test data.

The final classification tree has picked five predictors. There is a 24% likelihood that the borrower would be classified as bad if the duration of the instalments is more than 44 months and the checking account of the borrower has less than 200 dollars in amount. Similarly, there is a 15% likelihood that the borrower will be classified as bad if the credit amount is less than 1868 dollars, the duration of the instalments is between 12 to 44 months with the reason for credit is for domestic appliances, education, new car, or repairs. The tree will classify 45% of the dataset as good borrowers with a likelihood of 87% if the below points are satisfied
     1.  The checking account is greater than 200 dollars
     2.  There is no checking account present.

### Random Forest
The classification of a borrower is done using the random forest algorithm. Random forest’s trace functionality was used to determine the optimal number of trees required for the classification task. Random forests comprising of 5000 trees were run to check the steady decrease in value with an out of bag error rate of 22.7% of the model and the model was tested with the test data. The model was built on 3450 different trees and each tree would have a different bootstrapped sample of observations. As the number of predictors is 19 (p) then each tree will be built using either 4 or 5 predictors. The confusion matrix for the random forest model built for classification.

### Gradient Boosting Model
The data was converted into the numeric format and then factored for the model input. As the target variable has only binary values the distribution used was the Bernoulli distribution with basic n-trees value as 10000 and the initial number of splits it performs on the tree is 4. The two most important features which explain the maximum variance in the dataset is credit amount and credit purpose.

Every model was run and tested using a training dataset. For each model the confusion matrix was generated, where, accuracy, precision, recall and F1 score was calculated. The precedence was given to recall as it is probably worse to not receive less or no money from the borrower, which could be a financial loss. So, in such scenarios, a financial institute should avoid lending money in the first place. Since the impact of errors caused is important so False Negatives (FNs) is assessed for each model significantly, it makes sense to select a model that has as few FNs as possible. The F1 Score is taken as the second measuring criteria’s as it sums up the predictive performance of the model based on precision and recall. The scores of each model were assessed which depicted the score of recall and the F1 score is best for the random forest model & hence it will be chosen over other models.

# Unsupervised Principal Component Analysis (PCA)
The PCA model was run on the continuous variables to understand the variability of observations as much as possible. By visualizing the PCA plot, it can be interpreted as the credit amount taken by the borrower and the duration of months are highly correlated with each other. So, the more the credit amount taken by the customer the duration of the credit return would be more. Similarly, variables like age, number of credits and years of residence are correlated

# Final Model Results
The random forest model gave the best result output in comparison to the other models. The model’s F1 score with all the predictors before the feature selection was 0.84 and the recall score was 0.93. The recall score indicates that the model has a low false-positive rate which indicates that a few observations from the test dataset were predicted as good borrowers but, these borrowers have historically defaulted in loan. The model was run with the selected features using random forest during feature selection. These selected features and an optimal number of trees set to the model gave an F1 score of 0.85 and a recall of 0.94. The features like borrower’s checking and savings account status, duration of months to pay back the loan, the credit history of the borrower, the purpose of the loan, the amount borrowed and the years of employment of the borrower have more importance in predicting if the borrower will be defaulter or not. The out of bag error for the final model is 23.43% and the confusion matrix for the final model

# Conclusion
Fraud analytics has increasingly become an area of focus for financial institutions. All the banks and other lending firms have allocated resources for credit risk mitigation and prevention. According to the statistics, the loss was to the tune of 24 billion dollars in 2018 due to payment fraud worldwide. To address this growing area of fraud, credit lending companies and banks require timely detection and prevention of potentially fraudulent loan borrowing.

According to the study, the important predictors in evaluating the risk of fraud are the status of the checking and saving accounts, credit duration and credit amount. These insights can be utilized by the officials to not extend credit cards or loans to the customers whose checking/saving account information is not available and have a poor credit history.

The financial personnel should be trained to understand the factors affecting the likelihood of a person being a loan defaulter which would help them understand borrower's intention appropriately.

The data being used shows around 36% of the total lent amount from the financial firm was defaulted by the borrowers, and these were primarily defaulted by people taking less credit amount. This trend is followed by the defaulters, as defaulting a low credit amount doesn’t have severe repercussions. So, the financial institutions should implement stricter laws for all the borrowers and consider trending factors to improvise the accuracy of the model.

This model can be further enhanced by trying different techniques and unsupervised clustering methods to identify the similarity between the predictors which can be used to predict the defaulter appropriately.
